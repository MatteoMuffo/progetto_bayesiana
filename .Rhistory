library('RColorBrewer') # visualisation
library('corrplot') # visualisation
# general data manipulation
library('dplyr') # data manipulation
library('readr') # input/output
library('data.table') # data manipulation
library('tibble') # data wrangling
library('tidyr') # data wrangling
library('stringr') # string manipulation
library('forcats') # factor manipulation
# specific visualisation
library('ggfortify') # visualisation
library('ggrepel') # visualisation
library('treemapify') # visualisation ----- not available for my R version (3.3.3)
library('ggforce') # visualisation
# specific data manipulation
library('broom') # data wrangling
library('purrr') # string manipulation
# Date plus forecast
library('lubridate') # date and time
library('timeDate') # date and time
# general visualisation
library('ggplot2') # visualisation
library('scales') # visualisation
library('grid') # visualisation
library('gridExtra') # visualisation
library('RColorBrewer') # visualisation
library('corrplot') # visualisation
# general data manipulation
library('dplyr') # data manipulation
library('readr') # input/output
library('data.table') # data manipulation
library('tibble') # data wrangling
library('tidyr') # data wrangling
library('stringr') # string manipulation
library('forcats') # factor manipulation
# specific visualisation
library('ggfortify') # visualisation
library('ggrepel') # visualisation
library('treemapify') # visualisation ----- not available for my R version (3.3.3)
library('ggforce') # visualisation
# specific data manipulation
library('broom') # data wrangling
library('purrr') # string manipulation
# Date plus forecast
library('lubridate') # date and time
library('timeDate') # date and time
# general visualisation
library('ggplot2') # visualisation
library('scales') # visualisation
library('grid') # visualisation
library('gridExtra') # visualisation
library('RColorBrewer') # visualisation
library('corrplot') # visualisation
# general data manipulation
library('dplyr') # data manipulation
library('readr') # input/output
library('data.table') # data manipulation
library('tibble') # data wrangling
library('tidyr') # data wrangling
library('stringr') # string manipulation
library('forcats') # factor manipulation
# specific visualisation
library('ggfortify') # visualisation
library('ggrepel') # visualisation
library('treemapify') # visualisation ----- not available for my R version (3.3.3)
library('ggforce') # visualisation
# specific data manipulation
library('broom') # data wrangling
library('purrr') # string manipulation
# Date plus forecast
library('lubridate') # date and time
library('timeDate') # date and time
system('clang++ -v')
dotR <- file.path(Sys.getenv("HOME"), ".R")
if (!file.exists(dotR)) dir.create(dotR)
M <- file.path(dotR, "Makevars")
if (!file.exists(M)) file.create(M)
cat("\nCXXFLAGS=-O3 -mtune=native -march=native -Wno-unused-variable -Wno-unused-function",
file = M, sep = "\n", append = TRUE)
dotR <- file.path(Sys.getenv("HOME"), ".R")
if (!file.exists(dotR)) dir.create(dotR)
M <- file.path(dotR, "Makevars")
if (!file.exists(M)) file.create(M)
cat("\nCXXFLAGS=-O3 -mtune=native -march=native -Wno-unused-variable -Wno-unused-function",
file = M, sep = "\n", append = TRUE)
cat("\nCC=clang", "CXX=clang++ -arch x86_64 -ftemplate-depth-256",
file = M, sep = "\n", append = TRUE)
cat(readLines(M), sep = "\n")
cat(M)
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies=TRUE)
# Load the library
library(rstan)   # to interface R with STAN
knitr::opts_chunk$set(echo = FALSE)
## define base for the graphs and store in object 'p'
p6 <- ggplot(data = Gdata[!is.na(Rim_area) & !is.na(RNFL_average),], aes(x = Rim_area, y = RNFL_average, color= factor(Patient) )  )
library(ggplot2)
## define base for the graphs and store in object 'p'
p5 <- ggplot(data = Gdata[!is.na(PSD) & !is.na(RNFL_average),], aes(x = PSD, y = RNFL_average,  color= factor(Patient) )  )
knitr::opts_chunk$set(echo = FALSE)
setwd("~/Documents/universita/bayesian_statistics-Guglielmi/GLAUCOMA_PROJECT/src/analisi_exp_markdown/")
Gdata=read.table("../../data/data.csv", header=T,fill=T,sep=",")
10/27*100
(27-10)/27*100
(68-15)/68*100
(12-8)/12*100
(60-25)/60*100
(30-17.5)/30
28,26
target=113-6.5
target/11*3
(29.05*108-28.26*62)/(108-62)
(target_mean*108-28.26*62)/(108-62)
target_mean=29
(target_mean*108-28.26*62)/(108-62)
29*11/3
29*11/3+7
100+111
11
1
1
1
1
1
113-7
106/11*3
target_mean=28.90909
(target_mean*108-28.26*62)/(108-62)
105.5/11*3
target_mean=105.5/11*3
(target_mean*108-28.26*62)/(108-62)
(28*108-28.26*62)/(108-62)
28*11/3
+7
28*11/3+7
28.26*11/3
+7
28.26*11/3+7
28.26*11/3+75.9
28.26*11/3+5.9
109.5-6
103.6/11*3
104+5
104+5.5
104/11*3
28.36*11/3
+6
28.36*11/3+7
3.232/cos/(0.5222)
3.232/cos(0.5222)
qnorm(0.1106)
qnorm(2.27)
qnorm(0)
pnorm(0)
pnorm(2.27)
setwd("~/Documents/universita/bayesian_statistics-Guglielmi/GLAUCOMA_PROJECT/src")
load("../R_object/MDP_2.RData")
library(coda)        # pacchetto per analizzare catene
library(plotrix)     # per fare plot CIs
data=as.matrix(outputRegress) # trasformo il dataframe in matrice
data=data.frame(data)
attach(data)
n.chain=dim(data)[1]   # lunghezza catena (final sample size)
tmp=data.out[,grep("b.1.", names(data.out), fixed=TRUE)]
names(tmp)
b=tmp
tmp=melt(b)
head(tmp)
colnames(tmp) = c("Parameter", "value")
CI.b = apply(b, 2, quantile, c(0.05, 0.95))
CI.b
p=ggs_caterpillar(tmp, thick_ci = c(0.05, 0.95), thin_ci = c(0.025, 0.975))
p  + geom_vline(xintercept=0, col="orange")
# 90% CI random coefficients: random intercept
tmp=data.out[,grep("b.1.", names(data.out), fixed=TRUE)]
data=as.matrix(outputRegress) # trasformo il dataframe in matrice
data=data.frame(data)
attach(data)
n.chain=dim(data)[1]   # lunghezza catena (final sample size)
data.out=data
# 90% CI random coefficients: random intercept
tmp=data.out[,grep("b.1.", names(data.out), fixed=TRUE)]
names(tmp)
b=tmp
tmp=melt(b)
head(tmp)
colnames(tmp) = c("Parameter", "value")
library(ggplot2)
library(ggmcmc)
library(reshape)
# 90% CI random coefficients: random intercept
tmp=data.out[,grep("b.1.", names(data.out), fixed=TRUE)]
names(tmp)
b=tmp
# let's check the traceplots of random b1
outputRegress_mcmc = as.mcmc(data[,grep("slope", names(data), fixed=TRUE)])
# 90% CI random coefficients: random intercept
tmp=data.out[,grep("slope.", names(data.out), fixed=TRUE)]
names(tmp)
b=tmp
tmp=melt(b)
head(tmp)
colnames(tmp) = c("Parameter", "value")
CI.b = apply(b, 2, quantile, c(0.05, 0.95))
CI.b
p=ggs_caterpillar(tmp, thick_ci = c(0.05, 0.95), thin_ci = c(0.025, 0.975))
p  + geom_vline(xintercept=0, col="orange")
setwd("~/Documents/universita/bayesian_statistics-Guglielmi/GLAUCOMA_PROJECT/src")
load("../R_object/MDP_1.RData")
library(coda)        # pacchetto per analizzare catene
library(plotrix)     # per fare plot CIs
data=as.matrix(outputRegress) # trasformo il dataframe in matrice
data=data.frame(data)
attach(data)
n.chain=dim(data)[1]   # lunghezza catena (final sample size)
# 90% CI random coefficients: random intercept
tmp=data.out[,grep("b0", names(data.out), fixed=TRUE)]
# 90% CI random coefficients: random intercept
tmp=data[,grep("b0", names(data.out), fixed=TRUE)]
# 90% CI random coefficients: random intercept
tmp=data[,grep("b0", names(data), fixed=TRUE)]
names(tmp)
b=tmp
tmp=melt(b)
head(tmp)
##################### 90% CI RANDOM COEFFICIENTS #####################
library(ggplot2)
library(ggmcmc)
library(reshape)
# 90% CI random coefficients: random intercept
tmp=data[,grep("b0", names(data), fixed=TRUE)]
names(tmp)
b=tmp
tmp=melt(b)
head(tmp)
colnames(tmp) = c("Parameter", "value")
CI.b = apply(b, 2, quantile, c(0.05, 0.95))
CI.b
p=ggs_caterpillar(tmp, thick_ci = c(0.05, 0.95), thin_ci = c(0.025, 0.975))
p  + geom_vline(xintercept=0, col="orange")
# 90% CI random coefficients
tmp=data.out[,grep("slope", names(data.out), fixed=TRUE)]
# 90% CI random coefficients
tmp=data[,grep("slope", names(data), fixed=TRUE)]
names(tmp)
b=tmp
tmp=melt(b)
head(tmp)
colnames(tmp) = c("Parameter", "value")
CI.b = apply(b, 2, quantile, c(0.05, 0.95))
CI.b
p=ggs_caterpillar(tmp, thick_ci = c(0.05, 0.95), thin_ci = c(0.025, 0.975))
p  + geom_vline(xintercept=0, col="orange")
load("../R_object/model_14.RData")
library(coda)        # pacchetto per analizzare catene
library(plotrix)     # per fare plot CIs
data=as.matrix(outputRegress) # trasformo il dataframe in matrice
data=data.frame(data)
attach(data)
n.chain=dim(data)[1]   # lunghezza catena (final sample size)
names(data)
# let's check the traceplots of random b1
outputRegress_mcmc = as.mcmc(data[,grep("b.1", names(data), fixed=TRUE)])
hh=c(kk,1046)# patients i has rows from hh[i]+1 to hh[i+1]
mu=data.out[,grep("mu", names(data.out), fixed=TRUE)]
# plot i-esimi pazienti
i1=50
i2=51
i3=101
mu_pat_i=mu[,(hh[i1]+1):hh[i1+1]]
pred.mean=apply(mu_pat_i,2,mean)
lower=apply(mu_pat_i,2,quantile, 0.05)
upper=apply(mu_pat_i,2,quantile, 0.95)
plotdata <- data.frame(obs=RNFL_average[which(Patient==unique(Patient)[i1])], x=visit2[which(Patient==unique(Patient)[i1])], y=pred.mean, lower = lower, upper = upper)
attach(mydata)
############# RESIDUI BAYESIANI #############
mu=data[,grep("mu", names(data), fixed=TRUE)]
pred.mean=apply(mu,2,mean)
pred.sd=apply(mu,2,sd)
bres= (pred.mean- RNFL_average)/pred.sd   # residui bayesiani
out2 = (abs(bres) > 2) #as a reference value we take 2, (or 1.8)
length(which(out2==TRUE))
error=abs(pred.mean- RNFL_average)
mean.error=mean(error)
mean(error)
median.error=median(error)
median.error
# Predictive goodness-of-fit: SUM (or MEAN) of the predictive Bayesian residuals
# to compare different models
# The "best" model is the one with the smallest value for this index
MEAN.RES.BAYES=mean(bres^2)
MEAN.RES.BAYES
MEDIAN.RES.BAYES=median(bres^2)
MEDIAN.RES.BAYES
plot(sort(bres^2))
mean(error)
median.error=median(error)
median.error
# Predictive goodness-of-fit: SUM (or MEAN) of the predictive Bayesian residuals
# to compare different models
# The "best" model is the one with the smallest value for this index
MEAN.RES.BAYES=mean(bres^2)
MEAN.RES.BAYES
MEDIAN.RES.BAYES=median(bres^2)
MEDIAN.RES.BAYES
plot(sort(bres^2))
#calcolo LPML
n=dim(mydata)[1]
n
cpo=seq(1,n)
names(data)
first.b1.pos=which(names(data)=="b.1.1.")
mcmc.std.dev=data[,grep("sigma0", names(data), fixed=TRUE)]
beta= data[,grep("beta", names(data), fixed=TRUE)]
tmp=X%*%t(beta)
dim(tmp)
npat=length(unique(Patient))
for (i in 1:npat){
b1=data[,first.b1.pos+2*(i-1)]
b2=data[,first.b1.pos+1+2*(i-1)]
tmp_b=cbind(b1,b2)
for(j in 1:numerosity[i])
{
pred=tmp[kk[i]+j,] + Z[kk[i]+j,]%*%t(tmp_b)
cpo[kk[i]+j]=1/mean(1/dnorm(RNFL_average[kk[i]+j], pred , mcmc.std.dev))
}
}
LPML=sum(log(cpo))
LPML
sum(cpo)
median(cpo)
rm(list=ls())
rm(list=ls())
load("../R_object/Glaucoma_better_data.RData")
attach(mydata)
################JAGGAMENTO#######################
library(rjags)
# Compute useful values
numerosity<-as.integer(table(Patient))
kk=rep(0,length(unique(Patient)))
kk[1]=0
for (i in 2:length(unique(Patient))){
kk[i]=kk[i-1]+numerosity[i-1]
}
#covariates with fixed coefficents
X=cbind(
rep(1,length(Patient)),  # b1 (intercept)
Black,               #beta2
#Hispanic,            #beta3
familiarity_yes,     #beta4
Sex,                 #beta5
#POAG,                #beta6
#Hypertension,        #beta7
#HyperLipidemia,      #beta8
#Cardiovascular_Dz,   #beta9
age65,               #beta10
#prostaglandin,       #beta11
brimonidine,         #beta12
#timolol,             #beta13
#IOP,                     #beta14
MD,                      #beta15
Vert_integrated_rim_area__vol_,     #beta17
Horz_integrated_rim_width__area_   #beta18
#Rim_area               #beta19
)
#covariates with random coefficents
Z=cbind(
rep(1,length(Patient)),  # b1 (intercept)
#macular_volume,          # b2
visit2                   # time
)
# Hyperparameters:
mu0=rep(0, dim(X)[2])
c=50
S0=c*solve(t(X)%*%X) # Zellner prior
b0=rep(0,dim(Z)[2])
R=diag(rep(1, dim(Z)[2]))
#p=dim(Z)[2]
#p=100
p=30
data=list( y=RNFL_average, X=X, Z=Z, npat= length(unique(Patient)), nrow_b=dim(Z)[2],
mu0=mu0, S0=S0, b0=b0, R=R, p=p, numerosity = numerosity, kk=kk)      # dati che passo a jags
#fixed coefficients initialization:
beta= rep(0,dim(X)[2])
#random coefficients initialization (row_i= coefficients b_i):
b= matrix(0,nrow=dim(Z)[2], ncol=length(unique(Patient)))
invD=p*solve(R)
inits = function() {list( beta=beta, b=b, invD=invD, sigma0=50,sigma1=50)}
modelRegress=jags.model("data4.bug",data=data,inits=inits,n.adapt=1000,n.chains=1)
update(modelRegress,n.iter=19000)
variable.names=c("beta", "b", "sigma0","sigma1","mu","p2")
n.iter=130000
thin=40
library(coda)
library(plotrix)
outputRegress=coda.samples(model=modelRegress,variable.names=variable.names,n.iter=n.iter,thin=thin)
#outputRegress_mcmc <- as.mcmc(outputRegress)
data.out=as.matrix(outputRegress)
data.out=data.frame(data.out)
attach(data.out)
n.chain=dim(data.out)[1]
n.chain
#summary(data.out)
#head(data.out)
save.image("../R_object/model_14.RData")
library(coda)        # pacchetto per analizzare catene
library(plotrix)     # per fare plot CIs
data=as.matrix(outputRegress) # trasformo il dataframe in matrice
data=data.frame(data)
attach(data)
n.chain=dim(data)[1]   # lunghezza catena (final sample size)
names(data)
# let's check the traceplots of random b1
outputRegress_mcmc = as.mcmc(data[,grep("b.1", names(data), fixed=TRUE)])
plot(outputRegress_mcmc)
############# RESIDUI BAYESIANI #############
mu=data[,grep("mu", names(data), fixed=TRUE)]
pred.mean=apply(mu,2,mean)
pred.sd=apply(mu,2,sd)
bres= (pred.mean- RNFL_average)/pred.sd   # residui bayesiani
out2 = (abs(bres) > 2) #as a reference value we take 2, (or 1.8)
length(which(out2==TRUE))
error=abs(pred.mean- RNFL_average)
mean.error=mean(error)
mean(error)
median.error=median(error)
median.error
# Predictive goodness-of-fit: SUM (or MEAN) of the predictive Bayesian residuals
# to compare different models
# The "best" model is the one with the smallest value for this index
MEAN.RES.BAYES=mean(bres^2)
MEAN.RES.BAYES
MEDIAN.RES.BAYES=median(bres^2)
#calcolo LPML
n=dim(mydata)[1]
n
cpo=seq(1,n)
names(data)
first.b1.pos=which(names(data)=="b.1.1.")
mcmc.std.dev=data[,grep("sigma0", names(data), fixed=TRUE)]
beta= data[,grep("beta", names(data), fixed=TRUE)]
tmp=X%*%t(beta)
dim(tmp)
npat=length(unique(Patient))
for (i in 1:npat){
b1=data[,first.b1.pos+2*(i-1)]
b2=data[,first.b1.pos+1+2*(i-1)]
tmp_b=cbind(b1,b2)
for(j in 1:numerosity[i])
{
pred=tmp[kk[i]+j,] + Z[kk[i]+j,]%*%t(tmp_b)
cpo[kk[i]+j]=1/mean(1/dnorm(RNFL_average[kk[i]+j], pred , mcmc.std.dev))
}
}
LPML=sum(log(cpo))
LPML
sum(cpo)
median(cpo)
mean(cpo)
names(data)
first.b1.pos=which(names(data)=="b.1.1.")
beta= data[,grep("beta", names(data), fixed=TRUE)]
tmp=X%*%t(beta)
npat=length(unique(Patient))
for (i in 1:npat){
b1=data[,first.b1.pos+2*(i-1)]
b2=data[,first.b1.pos+1+2*(i-1)]
tmp_b=cbind(b1,b2)
for(j in 1:numerosity[i])
{
pred[kk[i]+j]=tmp[kk[i]+j,] + Z[kk[i]+j,]%*%t(tmp_b)
}
}
sigma.hat=mean(data[,grep("sigma0", names(data), fixed=TRUE)])
loglik=0
for (k in 1:n){
loglik=loglik+dnorm(RNFL_average[k],mean=pred[k], sd =sigma.hat , log=TRUE)
}
# loglikelyhood:
loglik
# r is the number of parameters
r=length(names(data[,grep("b.", names(data), fixed=TRUE)])) + length(names(data[,grep("beta", names(data), fixed=TRUE)]))
#AIC
AIC=2*loglik-2*r
AIC
#BIC
BIC=2*loglik-r*log(n)
BIC
which(cpo<10^-5)
which(cpo<10^-5)
library(coda)        # pacchetto per analizzare catene
library(plotrix)     # per fare plot CIs
data=as.matrix(outputRegress) # trasformo il dataframe in matrice
data=data.frame(data)
attach(data)
n.chain=dim(data)[1]   # lunghezza catena (final sample size)
names(data)
# let's check the traceplots of random b1
outputRegress_mcmc = as.mcmc(data[,grep("b.1", names(data), fixed=TRUE)])
quartz()
plot(outputRegress_mcmc)
# some autocorrelations plots
quartz()
acfplot(outputRegress_mcmc[,1:10])
# let's check the traceplots of random b2
outputRegress_mcmc = as.mcmc(data[,grep("b.2", names(data), fixed=TRUE)])
acfplot(outputRegress_mcmc[,1:10])
# some autocorrelations plots
quartz()
acfplot(outputRegress_mcmc[,1:10])
rm(list=ls())
graphics.off()
